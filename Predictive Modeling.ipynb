{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e97fe74",
   "metadata": {},
   "source": [
    "# **Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1241109",
   "metadata": {},
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e2cd85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numpy\n",
    "import numpy as np\n",
    "from numpy import median\n",
    "\n",
    "#Pandas\n",
    "import pandas as pd\n",
    "\n",
    "#Seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "#matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "\n",
    "#Sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "#Scipy\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "#Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8ba1b4",
   "metadata": {},
   "source": [
    "# **Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7dbcc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in the data from the previous notebook\n",
    "fd = pd.read_csv('fd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "080392f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order #</th>\n",
       "      <th>Transaction Type</th>\n",
       "      <th>Order Time</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Delivery Date</th>\n",
       "      <th>Product Total</th>\n",
       "      <th>Delivery</th>\n",
       "      <th>Nontaxable Delivery</th>\n",
       "      <th>Wire Out Fee</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Gift Cards</th>\n",
       "      <th>Tax</th>\n",
       "      <th>Tips</th>\n",
       "      <th>Grand Total</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Order Type</th>\n",
       "      <th>Order Method</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100017453</td>\n",
       "      <td>Sale</td>\n",
       "      <td>03:28:16PM Sat</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>815.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>894.46</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Taken</td>\n",
       "      <td>Phone</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100017452</td>\n",
       "      <td>Sale</td>\n",
       "      <td>03:16:50PM Sat</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>249.90</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-124.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.13</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Taken</td>\n",
       "      <td>Walk-In</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100017451</td>\n",
       "      <td>Sale</td>\n",
       "      <td>02:58:53PM Sat</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>24.95</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.38</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Taken</td>\n",
       "      <td>Walk-In</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100017450</td>\n",
       "      <td>Sale</td>\n",
       "      <td>02:54:45PM Sat</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>635.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>696.91</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Taken</td>\n",
       "      <td>Phone</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100017202</td>\n",
       "      <td>Sale</td>\n",
       "      <td>02:48:15PM Sat</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>2018-12-23</td>\n",
       "      <td>702.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>795.45</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>Walk-In</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Order # Transaction Type      Order Time  Order Date Delivery Date  \\\n",
       "0  100017453             Sale  03:28:16PM Sat  2018-12-29    2018-12-29   \n",
       "1  100017452             Sale  03:16:50PM Sat  2018-12-29    2018-12-29   \n",
       "2  100017451             Sale  02:58:53PM Sat  2018-12-29    2018-12-29   \n",
       "3  100017450             Sale  02:54:45PM Sat  2018-12-29    2018-12-29   \n",
       "4  100017202             Sale  02:48:15PM Sat  2018-12-29    2018-12-23   \n",
       "\n",
       "   Product Total Delivery  Nontaxable Delivery  Wire Out Fee  Discount  \\\n",
       "0         815.00    $0.00                  0.0           0.0      0.00   \n",
       "1         249.90    $0.00                  0.0           0.0   -124.96   \n",
       "2          24.95    $0.00                  0.0           0.0      0.00   \n",
       "3         635.00    $0.00                  0.0           0.0      0.00   \n",
       "4         702.00    $0.00                 25.0           0.0      0.00   \n",
       "\n",
       "   Gift Cards    Tax  Tips  Grand Total Payment Method Order Type  \\\n",
       "0         0.0  79.46   0.0       894.46    Credit Card      Taken   \n",
       "1         0.0  12.19   0.0       137.13    Credit Card      Taken   \n",
       "2         0.0   2.43   0.0        27.38    Credit Card      Taken   \n",
       "3         0.0  61.91   0.0       696.91    Credit Card      Taken   \n",
       "4         0.0  68.45   0.0       795.45    Credit Card   Delivery   \n",
       "\n",
       "  Order Method  Year  \n",
       "0        Phone  2018  \n",
       "1      Walk-In  2018  \n",
       "2      Walk-In  2018  \n",
       "3        Phone  2018  \n",
       "4      Walk-In  2018  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Taking a glance at the data to ensure it was laoded properly\n",
    "fd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "509e3245",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46062 entries, 0 to 46061\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Order #              46062 non-null  int64  \n",
      " 1   Transaction Type     46062 non-null  object \n",
      " 2   Order Time           46062 non-null  object \n",
      " 3   Order Date           46062 non-null  object \n",
      " 4   Delivery Date        46062 non-null  object \n",
      " 5   Product Total        46062 non-null  float64\n",
      " 6   Delivery             46062 non-null  object \n",
      " 7   Nontaxable Delivery  46062 non-null  float64\n",
      " 8   Wire Out Fee         46062 non-null  float64\n",
      " 9   Discount             46062 non-null  float64\n",
      " 10  Gift Cards           46062 non-null  float64\n",
      " 11  Tax                  46062 non-null  float64\n",
      " 12  Tips                 46062 non-null  float64\n",
      " 13  Grand Total          46062 non-null  float64\n",
      " 14  Payment Method       46062 non-null  object \n",
      " 15  Order Type           46062 non-null  object \n",
      " 16  Order Method         46062 non-null  object \n",
      " 17  Year                 46062 non-null  int64  \n",
      "dtypes: float64(8), int64(2), object(8)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Looking at the data types  and ensure there are no missing values\n",
    "fd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1789ee63",
   "metadata": {},
   "source": [
    "# **Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6bed98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out the years 2016 & 2017 because the data for those years is incomplete, and also could be considered irrelevant because of how old it is.\n",
    "filtered_data = fd[(fd['Year'] != 2016) & (fd['Year'] != 2017)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9afd2ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting up the 'Delivery Date' column into indiviual columns for year, month, and day to prepare the data for modeling.\n",
    "fd['Delivery Date'] = pd.to_datetime(fd['Delivery Date'])\n",
    "fd['Delivery Year'] = fd['Delivery Date'].dt.year\n",
    "fd['Delivery Day'] = fd['Delivery Date'].dt.day\n",
    "fd['Delivery Month'] = fd['Delivery Date'].dt.month\n",
    "\n",
    "#Spliting up the 'Order Date' column into indiviual columns for year, month, and day to prepare the data for modeling.\n",
    "fd['Order Date'] = pd.to_datetime(fd['Order Date'])\n",
    "fd['Order Year'] = fd['Order Date'].dt.year\n",
    "fd['Order Day'] = fd['Order Date'].dt.day\n",
    "fd['Order Month'] = fd['Order Date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bedaa9f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46062 entries, 0 to 46061\n",
      "Data columns (total 24 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   Order #              46062 non-null  int64         \n",
      " 1   Transaction Type     46062 non-null  object        \n",
      " 2   Order Time           46062 non-null  object        \n",
      " 3   Order Date           46062 non-null  datetime64[ns]\n",
      " 4   Delivery Date        46062 non-null  datetime64[ns]\n",
      " 5   Product Total        46062 non-null  float64       \n",
      " 6   Delivery             46062 non-null  object        \n",
      " 7   Nontaxable Delivery  46062 non-null  float64       \n",
      " 8   Wire Out Fee         46062 non-null  float64       \n",
      " 9   Discount             46062 non-null  float64       \n",
      " 10  Gift Cards           46062 non-null  float64       \n",
      " 11  Tax                  46062 non-null  float64       \n",
      " 12  Tips                 46062 non-null  float64       \n",
      " 13  Grand Total          46062 non-null  float64       \n",
      " 14  Payment Method       46062 non-null  object        \n",
      " 15  Order Type           46062 non-null  object        \n",
      " 16  Order Method         46062 non-null  object        \n",
      " 17  Year                 46062 non-null  int64         \n",
      " 18  Delivery Year        46062 non-null  int64         \n",
      " 19  Delivery Day         46062 non-null  int64         \n",
      " 20  Delivery Month       46062 non-null  int64         \n",
      " 21  Order Year           46062 non-null  int64         \n",
      " 22  Order Day            46062 non-null  int64         \n",
      " 23  Order Month          46062 non-null  int64         \n",
      "dtypes: datetime64[ns](2), float64(8), int64(8), object(6)\n",
      "memory usage: 8.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#Confirming the new columns were formed properly\n",
    "fd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac51040",
   "metadata": {},
   "source": [
    "### **More Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00ad69ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0916663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to drop\n",
    "columns_to_drop = ['Tax', 'Wire Out Fee', 'Tips', 'Discount', 'Gift Cards', 'Nontaxable Delivery', 'Order Type', 'Delivery', 'Payment Method', 'Order Method', 'Delivery Date', 'Transaction Type', 'Order Time', 'Order Date', 'Year']\n",
    "fd.drop(columns=columns_to_drop, inplace=True)\n",
    "X_reduced = fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cee101f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46062 entries, 0 to 46061\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Order #         46062 non-null  int64  \n",
      " 1   Product Total   46062 non-null  float64\n",
      " 2   Grand Total     46062 non-null  float64\n",
      " 3   Delivery Year   46062 non-null  int64  \n",
      " 4   Delivery Day    46062 non-null  int64  \n",
      " 5   Delivery Month  46062 non-null  int64  \n",
      " 6   Order Year      46062 non-null  int64  \n",
      " 7   Order Day       46062 non-null  int64  \n",
      " 8   Order Month     46062 non-null  int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 3.2 MB\n"
     ]
    }
   ],
   "source": [
    "fd = X_reduced\n",
    "fd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bb850a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order #</th>\n",
       "      <th>Product Total</th>\n",
       "      <th>Grand Total</th>\n",
       "      <th>Delivery Year</th>\n",
       "      <th>Delivery Day</th>\n",
       "      <th>Delivery Month</th>\n",
       "      <th>Order Year</th>\n",
       "      <th>Order Day</th>\n",
       "      <th>Order Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100017453</td>\n",
       "      <td>815.00</td>\n",
       "      <td>894.46</td>\n",
       "      <td>2018</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>2018</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100017452</td>\n",
       "      <td>249.90</td>\n",
       "      <td>137.13</td>\n",
       "      <td>2018</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>2018</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100017451</td>\n",
       "      <td>24.95</td>\n",
       "      <td>27.38</td>\n",
       "      <td>2018</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>2018</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100017450</td>\n",
       "      <td>635.00</td>\n",
       "      <td>696.91</td>\n",
       "      <td>2018</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>2018</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100017202</td>\n",
       "      <td>702.00</td>\n",
       "      <td>795.45</td>\n",
       "      <td>2018</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>2018</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Order #  Product Total  Grand Total  Delivery Year  Delivery Day  \\\n",
       "0  100017453         815.00       894.46           2018            29   \n",
       "1  100017452         249.90       137.13           2018            29   \n",
       "2  100017451          24.95        27.38           2018            29   \n",
       "3  100017450         635.00       696.91           2018            29   \n",
       "4  100017202         702.00       795.45           2018            23   \n",
       "\n",
       "   Delivery Month  Order Year  Order Day  Order Month  \n",
       "0              12        2018         29           12  \n",
       "1              12        2018         29           12  \n",
       "2              12        2018         29           12  \n",
       "3              12        2018         29           12  \n",
       "4              12        2018         29           12  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e57a92",
   "metadata": {},
   "source": [
    "# **Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7e1bc9",
   "metadata": {},
   "source": [
    "### **Validation Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80110fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the target column to separate it from the features\n",
    "X = fd.drop(columns='Grand Total')\n",
    "y = fd['Grand Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c43971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b2c7a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputers\n",
    "freq_imputer = SimpleImputer(strategy='most_frequent')\n",
    "mean_imputer = SimpleImputer(strategy= 'mean')\n",
    "\n",
    "#Scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#OneHotEncoder\n",
    "ohe =OneHotEncoder(handle_unknown='ignore', sparse=True)\n",
    "\n",
    "#Create Selectors\n",
    "cat_selector = make_column_selector(dtype_include= 'object')\n",
    "num_selector = make_column_selector(dtype_include='number')\n",
    "\n",
    "# Numeric pipeline\n",
    "numeric_pipe = make_pipeline(mean_imputer, scaler)\n",
    "numeric_pipe\n",
    "\n",
    "#cat pipe\n",
    "categorical_pipe = make_pipeline(freq_imputer, ohe)\n",
    "categorical_pipe\n",
    "\n",
    "#Make tuples for preprocessing the categorical and numeric columns\n",
    "num_tuple = (numeric_pipe, num_selector)\n",
    "cat_tuple = (categorical_pipe, cat_selector)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d60b10f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Column Transformer\n",
    "preprocessor= make_column_transformer(num_tuple, cat_tuple, remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32f48e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order #             int64\n",
      "Product Total     float64\n",
      "Delivery Year       int64\n",
      "Delivery Day        int64\n",
      "Delivery Month      int64\n",
      "Order Year          int64\n",
      "Order Day           int64\n",
      "Order Month         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfac7986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "# Fit and transform the preprocessing on the training data\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the fitted preprocessor\n",
    "X_test_preprocessed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "571bdf98",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;pipeline-1&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer()),\n",
       "                                                 (&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000021C0AB5BA90&gt;),\n",
       "                                (&#x27;pipeline-2&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000021C0A98C820&gt;)])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;pipeline-1&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer()),\n",
       "                                                 (&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000021C0AB5BA90&gt;),\n",
       "                                (&#x27;pipeline-2&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000021C0A98C820&gt;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pipeline-1</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000021C0AB5BA90&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pipeline-2</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000021C0A98C820&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('pipeline-1',\n",
       "                                 Pipeline(steps=[('simpleimputer',\n",
       "                                                  SimpleImputer()),\n",
       "                                                 ('standardscaler',\n",
       "                                                  StandardScaler())]),\n",
       "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x0000021C0AB5BA90>),\n",
       "                                ('pipeline-2',\n",
       "                                 Pipeline(steps=[('simpleimputer',\n",
       "                                                  SimpleImputer(strategy='most_frequent')),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x0000021C0A98C820>)])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at how the preprocessor is organized\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bd5102f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_preprocessed shape: (34546, 8)\n",
      "y_train shape: (34546,)\n"
     ]
    }
   ],
   "source": [
    "# Ensuring the shape is correct\n",
    "print(\"X_train_preprocessed shape:\", X_train_preprocessed.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28444384",
   "metadata": {},
   "source": [
    "# **Linear Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41a41759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LinearRegression model\n",
    "regressor = LinearRegression()\n",
    "\n",
    "# Train the model using the preprocessed training sets\n",
    "regressor.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Make predictions for training data\n",
    "y_predictions_train = regressor.predict(X_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = regressor.predict(X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda42769",
   "metadata": {},
   "source": [
    "## **Tuning Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21f4a1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for evaluating Model preformance\n",
    "def evaluate_model(y_true, y_pred, split='training'):\n",
    "  \"\"\" prints RMSE, and R2 metrics, include which data split was evaluated\n",
    "\n",
    "  Args:\n",
    "    y_true: y-train or y-test\n",
    "    y_pred: result of model.predict(X)\n",
    "    split: which data split is being evaluate ['training','test']\n",
    "  \"\"\"\n",
    "\n",
    "  r2 = r2_score(y_true,y_pred)\n",
    "  mae = mean_absolute_error(y_true,y_pred)\n",
    "  mse = mean_squared_error(y_true, y_pred)\n",
    "  rmse = mean_squared_error(y_true,y_pred,squared=False)\n",
    "\n",
    "\n",
    "  print(f'Results for {split} data:')\n",
    "  print(f\"  - R^2 = {round(r2,3)}\")\n",
    "  print(f\"  - MAE = {round(mae,3)}\")\n",
    "  print(f\"  - MSE = {round(mse,3)}\")\n",
    "  print(f\"  - RMSE = {round(rmse,3)}\")\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "975c4e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for training data:\n",
      "  - R^2 = -68730864093.04\n",
      "  - MAE = 31272481.788\n",
      "  - MSE = 2770656803286024.5\n",
      "  - RMSE = 52637028.823\n",
      "\n",
      "Results for testing data:\n",
      "  - R^2 = 0.94\n",
      "  - MAE = 13.926\n",
      "  - MSE = 1812.342\n",
      "  - RMSE = 42.572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Evaluate model's performance\n",
    "evaluate_model(y_train, y_predictions_train,split='training')\n",
    "evaluate_model(y_test, y_pred,split='testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0eb4f8c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (Validation): 35.49055846857412\n",
      "Root Mean Squared Error (Test): 42.25580940793254\n"
     ]
    }
   ],
   "source": [
    "# Splitting the training set further for hyperparameter tuning\n",
    "X_train_tune, X_val, y_train_tune, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'fit_intercept': [True, False],  # Whether to calculate the intercept for this model\n",
    "    'normalize': [True, False],   # Whether to normalize the features before fitting the model\n",
    "    'copy_X': [True, False],          # Whether to copy the input data; set to False when using larger datasets\n",
    "    'positive': [True, False]         # Restrict coefficients to be positive\n",
    "}\n",
    "\n",
    "# Create the Linear Regression model\n",
    "model = regressor\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search = GridSearchCV(model, param_grid, cv=12, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Perform the grid search on the training data\n",
    "grid_search.fit(X_train_tune, y_train_tune)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred_val = best_model.predict(X_val)\n",
    "\n",
    "# Calculate RMSE for the validation set\n",
    "rmse_val = mean_squared_error(y_val, y_pred_val, squared=False)\n",
    "print(\"Root Mean Squared Error (Validation):\", rmse_val)\n",
    "\n",
    "# Now, you can use the best_model to predict on the test set and calculate RMSE\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "rmse_test = mean_squared_error(y_test, y_pred_test, squared=False)\n",
    "print(\"Root Mean Squared Error (Test):\", rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cd7ca3",
   "metadata": {},
   "source": [
    "# **Random Forest Regressor model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddaf3bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forrest Regressor Pipeline\n",
    "#Fitting the pipeline\n",
    "rf_tree_pipe = make_pipeline(preprocessor,RandomForestRegressor(random_state = 42))\n",
    "rf_tree_pipe.fit(X_train, y_train)\n",
    "\n",
    "## Get predictions for training and test data\n",
    "y_hat_train = rf_tree_pipe.predict(X_train)\n",
    "y_hat_test = rf_tree_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ee90472",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for training data:\n",
      "  - R^2 = 0.994\n",
      "  - MAE = 3.994\n",
      "  - MSE = 222.182\n",
      "  - RMSE = 14.906\n",
      "\n",
      "Results for testing data:\n",
      "  - R^2 = 0.916\n",
      "  - MAE = 10.446\n",
      "  - MSE = 2549.853\n",
      "  - RMSE = 50.496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Evaluate model's performance\n",
    "evaluate_model(y_train, y_hat_train,split='training')\n",
    "evaluate_model(y_test, y_hat_test,split='testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef36a8c3",
   "metadata": {},
   "source": [
    "## **Tuning Random Forest Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "054d84d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Train (max_depth=5)  Test (max_depth=5)  Train (max_depth=10)  \\\n",
      "202             0.974399            0.911653              0.990024   \n",
      "203             0.974406            0.911973              0.990024   \n",
      "204             0.974405            0.912040              0.990017   \n",
      "205             0.974413            0.911922              0.990034   \n",
      "206             0.974423            0.911896              0.990054   \n",
      "207             0.974427            0.911755              0.990068   \n",
      "208             0.974458            0.911664              0.990088   \n",
      "\n",
      "     Test (max_depth=10)  Train (max_depth=15)  Test (max_depth=15)  \n",
      "202             0.915894              0.993594             0.916199  \n",
      "203             0.916189              0.993593             0.916480  \n",
      "204             0.916244              0.993586             0.916565  \n",
      "205             0.916082              0.993601             0.916400  \n",
      "206             0.916026              0.993621             0.916337  \n",
      "207             0.915912              0.993627             0.916355  \n",
      "208             0.915855              0.993650             0.916240  \n"
     ]
    }
   ],
   "source": [
    "#create a range of max_depth values\n",
    "n_estimators = [202, 203, 204, 205, 206, 207, 208]\n",
    "\n",
    "max_depths = [5, 10, 15] \n",
    "\n",
    "#create a dataframe to store train and test scores.\n",
    "scores = pd.DataFrame(index=n_estimators)\n",
    "\n",
    "# Loop over the values in n_estimators\n",
    "for n in n_estimators:\n",
    "    for max_depth in max_depths:\n",
    "        # Fit a new model with max_depth\n",
    "        rf = RandomForestRegressor(random_state=42, n_estimators=n, max_depth=max_depth)\n",
    "\n",
    "        # Put the model into a pipeline\n",
    "        rf_pipe = make_pipeline(preprocessor, rf)\n",
    "\n",
    "        # Fit the model\n",
    "        rf_pipe.fit(X_train, y_train)\n",
    "\n",
    "        # Create prediction arrays\n",
    "        train_pred = rf_pipe.predict(X_train)\n",
    "        test_pred = rf_pipe.predict(X_test)\n",
    "\n",
    "        # Evaluate the model using R2 Score\n",
    "        train_r2score = r2_score(y_train, train_pred)\n",
    "        test_r2score = r2_score(y_test, test_pred)\n",
    "\n",
    "        # Store the scores in the scores dataframe\n",
    "        scores.loc[n, f'Train (max_depth={max_depth})'] = train_r2score\n",
    "        scores.loc[n, f'Test (max_depth={max_depth})'] = test_r2score\n",
    "\n",
    "# Print the scores dataframe\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d52c01a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train (max_depth=5)</th>\n",
       "      <th>Test (max_depth=5)</th>\n",
       "      <th>Train (max_depth=10)</th>\n",
       "      <th>Test (max_depth=10)</th>\n",
       "      <th>Train (max_depth=15)</th>\n",
       "      <th>Test (max_depth=15)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.974399</td>\n",
       "      <td>0.911653</td>\n",
       "      <td>0.990024</td>\n",
       "      <td>0.915894</td>\n",
       "      <td>0.993594</td>\n",
       "      <td>0.916199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.974406</td>\n",
       "      <td>0.911973</td>\n",
       "      <td>0.990024</td>\n",
       "      <td>0.916189</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.916480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.974405</td>\n",
       "      <td>0.912040</td>\n",
       "      <td>0.990017</td>\n",
       "      <td>0.916244</td>\n",
       "      <td>0.993586</td>\n",
       "      <td>0.916565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.974413</td>\n",
       "      <td>0.911922</td>\n",
       "      <td>0.990034</td>\n",
       "      <td>0.916082</td>\n",
       "      <td>0.993601</td>\n",
       "      <td>0.916400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.974423</td>\n",
       "      <td>0.911896</td>\n",
       "      <td>0.990054</td>\n",
       "      <td>0.916026</td>\n",
       "      <td>0.993621</td>\n",
       "      <td>0.916337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.974427</td>\n",
       "      <td>0.911755</td>\n",
       "      <td>0.990068</td>\n",
       "      <td>0.915912</td>\n",
       "      <td>0.993627</td>\n",
       "      <td>0.916355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.974458</td>\n",
       "      <td>0.911664</td>\n",
       "      <td>0.990088</td>\n",
       "      <td>0.915855</td>\n",
       "      <td>0.993650</td>\n",
       "      <td>0.916240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Train (max_depth=5)  Test (max_depth=5)  Train (max_depth=10)  \\\n",
       "202             0.974399            0.911653              0.990024   \n",
       "203             0.974406            0.911973              0.990024   \n",
       "204             0.974405            0.912040              0.990017   \n",
       "205             0.974413            0.911922              0.990034   \n",
       "206             0.974423            0.911896              0.990054   \n",
       "207             0.974427            0.911755              0.990068   \n",
       "208             0.974458            0.911664              0.990088   \n",
       "\n",
       "     Test (max_depth=10)  Train (max_depth=15)  Test (max_depth=15)  \n",
       "202             0.915894              0.993594             0.916199  \n",
       "203             0.916189              0.993593             0.916480  \n",
       "204             0.916244              0.993586             0.916565  \n",
       "205             0.916082              0.993601             0.916400  \n",
       "206             0.916026              0.993621             0.916337  \n",
       "207             0.915912              0.993627             0.916355  \n",
       "208             0.915855              0.993650             0.916240  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train and test scores\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8cf0499",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores for Random Forest Regressor\n",
      "Results for training data:\n",
      "  - R^2 = 0.974\n",
      "  - MAE = 12.19\n",
      "  - MSE = 1029.628\n",
      "  - RMSE = 32.088\n",
      "\n",
      "\n",
      "\n",
      "Testing Scores for Random forest Regressor\n",
      "Results for testing data:\n",
      "  - R^2 = 0.912\n",
      "  - MAE = 12.734\n",
      "  - MSE = 2683.05\n",
      "  - RMSE = 51.798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Obtaining the traing and test scores for random forest regression model\n",
    "best_rf = RandomForestRegressor(random_state = 42, n_estimators = n, max_depth=5)\n",
    "\n",
    "best_rf_pipe = make_pipeline(preprocessor, best_rf)\n",
    "\n",
    "best_rf_pipe.fit(X_train, y_train)\n",
    "\n",
    "print('Training Scores for Random Forest Regressor')\n",
    "evaluate_model(y_train, best_rf_pipe.predict(X_train), split = 'training')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('Testing Scores for Random forest Regressor')\n",
    "evaluate_model(y_test, best_rf_pipe.predict(X_test), split = 'testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0025b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (Test Set): 2544.076786043306\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data (X_test)\n",
    "y_pred_test = rf_pipe.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error on the test set\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "print(\"Mean Squared Error (Test Set):\", mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f208c1",
   "metadata": {},
   "source": [
    "# **Gradient Boosting Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "825262f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2141.0031974786943\n"
     ]
    }
   ],
   "source": [
    "gb_regressor = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Train the regressor on the training data\n",
    "gb_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = gb_regressor.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400be4a8",
   "metadata": {},
   "source": [
    "## **Tuning Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e554f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175ef52d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e3942b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7201016",
   "metadata": {},
   "source": [
    "# **XGBoost and LightGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1fec04b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Mean Squared Error: 2396.5998992992063\n"
     ]
    }
   ],
   "source": [
    "# You can adjust hyperparameters according to your needs\n",
    "lgb_regressor = lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Train the regressor on the training data\n",
    "lgb_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_lgb = lgb_regressor.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error on the test set\n",
    "mse_lgb = mean_squared_error(y_test, y_pred_lgb)\n",
    "print(\"LightGBM Mean Squared Error:\", mse_lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3423a3c3",
   "metadata": {},
   "source": [
    "## **Tuning Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd447db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2989d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92a84c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6aed433",
   "metadata": {},
   "source": [
    "# **K-Nearest Neighbors (KNN)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc74634d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Mean Squared Error: 3060.986796922195\n"
     ]
    }
   ],
   "source": [
    "# You can adjust the number of neighbors (n_neighbors) according to your needs\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Train the regressor on the training data\n",
    "knn_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = knn_regressor.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"KNN Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e309ca96",
   "metadata": {},
   "source": [
    "## **Tuning Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a472e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3626b228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bc7d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e01f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57b31675",
   "metadata": {},
   "source": [
    "# **Decision Tree Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df159a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Mean Squared Error: 2966.136488042898\n"
     ]
    }
   ],
   "source": [
    "# Create a Decision Tree Regressor.\n",
    "tree_regressor = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "\n",
    "# Training the regressor on the training data.\n",
    "tree_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test data.\n",
    "y_pred = tree_regressor.predict(X_test)\n",
    "\n",
    "# Calculating Mean Squared Error on the test set.\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Decision Tree Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ebb366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfa4d24f",
   "metadata": {},
   "source": [
    "## **Tuning Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ca8f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdb0c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31be5147",
   "metadata": {},
   "source": [
    "# **Neural Networks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33e144aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add input and hidden layers\n",
    "model.add(Dense(64, input_dim=1, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add output layer\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86dabff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 248, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential\" (type Sequential).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 8)\n    \n    Call arguments received by layer \"sequential\" (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 8), dtype=float64)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [37], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Train the model on the training data\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Make predictions on the test data\u001b[39;00m\n\u001b[0;32m      8\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filerbcvlltw.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 248, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential\" (type Sequential).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 8)\n    \n    Call arguments received by layer \"sequential\" (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 8), dtype=float64)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Neural Network Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1371d577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4bb6858",
   "metadata": {},
   "source": [
    "## **Tuning Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78ed853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391d9eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e97c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6f2d02d",
   "metadata": {},
   "source": [
    "# **Save Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0af049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the new dataframe to upload in the next notebook\n",
    "fd.to_csv('Predictions', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.516px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
